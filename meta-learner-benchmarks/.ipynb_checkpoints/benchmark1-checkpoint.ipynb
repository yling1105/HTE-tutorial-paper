{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV, MultiTaskElasticNetCV, ElasticNetCV, LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('causalml')\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='../Processed/final/'\n",
    "save_path='../Processed/final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_train, T_train, X_train, W_train)=pickle.load(open(data_path+'YTXW_train.pkl','rb'))\n",
    "(Y_test, T_test, X_test, W_test)=pickle.load(open(data_path+'YTXW_test.pkl','rb'))\n",
    "(Y_val, T_val, X_val, W_val)=pickle.load(open(data_path+'YTXW_val.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dx=pickle.load(open(data_path+'le_dx.pkl','rb'))\n",
    "le_patid=pickle.load(open(data_path+'le_patid.pkl','rb'))\n",
    "selected_patient_feature=['age_onset','obs_win','female']+['race__'+c for c in ['A','B','H','U','W']]\n",
    "rx2id = pickle.load(open(data_path+'drug_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Y,T,W,X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several steps:\n",
    "- Standardize age\n",
    "- Combine demographics with dx information \n",
    "- Set treatment and control group\n",
    "- Output a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def prepare(y, t, w, x, rx2id, target):\n",
    "    patid_temp = list(w['patid'].unique())\n",
    "    temp_le = preprocessing.LabelEncoder()\n",
    "    temp_le.fit(list(patid_temp))\n",
    "    w['row_idx'] = temp_le.transform(w['patid'])\n",
    "    \n",
    "    w_sparse = csr_matrix((w['log_count'], (w['row_idx'], w['phecode3'])))\n",
    "    w = w_sparse.toarray()\n",
    "    \n",
    "    x_temp = np.concatenate((w, x.values), axis=1)\n",
    "    \n",
    "    treatment_train = [0] * len(t)\n",
    "    temp_index = t.index\n",
    "    idx = 0\n",
    "\n",
    "    def get_classes(value):\n",
    "        return [k for k, v in rx2id.items() if v == value]\n",
    "\n",
    "    for i in temp_index:\n",
    "        classes = t.loc[i, 'antiasthma']\n",
    "        if (classes != target):\n",
    "            treatment_train[idx] = 'control'\n",
    "        else:\n",
    "            treatment_train[idx] = 'treatment'\n",
    "        idx += 1\n",
    "        \n",
    "    treatment = pd.DataFrame(treatment_train)\n",
    "    treatment.index = temp_index\n",
    "    treatment.columns = ['treatment']\n",
    "    \n",
    "    y = pd.DataFrame(y)\n",
    "    feature_df = pd.DataFrame(x_temp)\n",
    "    feature_df.index = y.index\n",
    "    \n",
    "    df = pd.concat([y, treatment, t, feature_df], axis=1)\n",
    "    df.index = np.arange(0, len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark (Agonist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 1\n",
    "df_val0 = prepare(Y_val, T_val, W_val, X_val, rx2id, target)\n",
    "df_test0 = prepare(Y_test, T_test, W_test, X_test, rx2id, target)\n",
    "df_train0 = prepare(Y_train, T_train, W_train, X_train, rx2id, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0 = df_train0.iloc[:, 5:]\n",
    "x_test0 = df_test0.iloc[:, 5:]\n",
    "x_val0 = df_val0.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, BaseSRegressor, BaseTRegressor\n",
    "from causalml.metrics import plot_gain, auuc_score\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from causalml.inference.meta import BaseSClassifier, BaseTClassifier, BaseXClassifier, BaseRClassifier\n",
    "from causalml.feature_selection.filters import FilterSelect\n",
    "\n",
    "from causalml.propensity import GradientBoostedPropensityModel\n",
    "from causalml.propensity import compute_propensity_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_train0['treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = [0] * len(t)\n",
    "for i in range(len(t)):\n",
    "    if t[i] == 'control':\n",
    "        treatment[i] = 0\n",
    "    else:\n",
    "        treatment[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = df_test0['treatment']\n",
    "treatment_test = [0] * len(t_test)\n",
    "for i in range(len(t_test)):\n",
    "    if t_test[i] == 'control':\n",
    "        treatment_test[i] = 0\n",
    "    else:\n",
    "        treatment_test[i] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val = df_val0['treatment']\n",
    "treatment_val = [0] * len(t_val)\n",
    "for i in range(len(t_val)):\n",
    "    if t_val[i] == 'control':\n",
    "        treatment_val[i] = 0\n",
    "    else:\n",
    "        treatment_val[i] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=3000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm = LogisticRegression(max_iter = 3000)\n",
    "glm.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred_p = glm.predict_proba(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = t_pred_p[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17856534, 0.26521402, 0.18511665, ..., 0.18130233, 0.30193069,\n",
       "       0.28136381])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5062264061349985"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, random_state=1105)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=6, random_state=1105)\n",
    "rf.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5207210522567012"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = rf.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              random_state=1105, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, random_state=1105, n_estimators=100)\n",
    "xgb.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5316721669555308"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = xgb.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(max_depth = 6, random_state = 1105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=6, random_state=1105)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5254803849410796"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = gbc.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(l1_ratio=0.1, max_iter=3000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_l1 = LogisticRegression(penalty='elasticnet', max_iter = 3000, solver='saga', l1_ratio=0.1)\n",
    "glm_l1.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred_p = glm_l1.predict_proba(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = t_pred_p[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5059583165159034"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = xgb.predict_proba(x_train0)[:, 1]\n",
    "df_train0['score'] = score\n",
    "df_train0['T'] = treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = list(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adrd</th>\n",
       "      <th>treatment</th>\n",
       "      <th>patid</th>\n",
       "      <th>antiasthma</th>\n",
       "      <th>log_count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>score</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>9722</td>\n",
       "      <td>1</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.883606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1232</td>\n",
       "      <td>5</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.117459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2220</td>\n",
       "      <td>1</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1806</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>9768</td>\n",
       "      <td>2</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>9185</td>\n",
       "      <td>3</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>1</td>\n",
       "      <td>treatment</td>\n",
       "      <td>9752</td>\n",
       "      <td>1</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>3868</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>6972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.465055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>4886</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6771 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adrd  treatment  patid  antiasthma  log_count    0         1         2  \\\n",
       "0        0  treatment   9722           1   1.945910  0.0  0.000000  0.000000   \n",
       "1        0    control   1232           5   1.386294  0.0  0.000000  1.098612   \n",
       "2        0  treatment   2220           1   3.583519  0.0  0.000000  0.000000   \n",
       "3        0    control   1806           4   0.693147  0.0  0.000000  0.000000   \n",
       "4        0    control   9768           2   1.386294  0.0  0.000000  0.000000   \n",
       "...    ...        ...    ...         ...        ...  ...       ...       ...   \n",
       "6766     0    control   9185           3   3.044522  0.0  0.000000  0.000000   \n",
       "6767     1  treatment   9752           1   1.609438  0.0  0.000000  0.693147   \n",
       "6768     0  treatment   3868           1   0.693147  0.0  0.000000  0.693147   \n",
       "6769     0  treatment   6972           1   0.693147  0.0  0.000000  0.693147   \n",
       "6770     0    control   4886           4   0.693147  0.0  0.693147  0.000000   \n",
       "\n",
       "             3         4  ...  241   242  243  244  245  246  247  248  \\\n",
       "0     0.000000  0.000000  ...  0.0  75.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1     1.098612  0.693147  ...  0.0  72.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2     0.000000  0.000000  ...  0.0  74.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3     0.000000  0.000000  ...  0.0  83.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "4     0.000000  0.000000  ...  0.0  84.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "...        ...       ...  ...  ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "6766  0.000000  0.000000  ...  0.0  90.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6767  0.000000  0.000000  ...  0.0  83.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6768  0.000000  0.000000  ...  0.0  88.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "6769  0.000000  0.000000  ...  0.0  89.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6770  1.098612  0.000000  ...  0.0  83.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "         score  T  \n",
       "0     0.883606  1  \n",
       "1     0.117459  0  \n",
       "2     0.906682  1  \n",
       "3     0.076535  0  \n",
       "4     0.076240  0  \n",
       "...        ... ..  \n",
       "6766  0.123111  0  \n",
       "6767  0.609267  1  \n",
       "6768  0.323897  1  \n",
       "6769  0.465055  1  \n",
       "6770  0.122138  0  \n",
       "\n",
       "[6771 rows x 256 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.match import NearestNeighborMatch, create_table_one\n",
    "\n",
    "psm = NearestNeighborMatch(replace=False,\n",
    "                           ratio=1,\n",
    "                           random_state=42)\n",
    "\n",
    "matched = psm.match(data=df_train0,\n",
    "                    treatment_col='T',\n",
    "                    score_cols=['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1746"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adrd</th>\n",
       "      <th>treatment</th>\n",
       "      <th>patid</th>\n",
       "      <th>antiasthma</th>\n",
       "      <th>log_count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>score</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4992</td>\n",
       "      <td>1</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.201304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>8502</td>\n",
       "      <td>1</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2809</td>\n",
       "      <td>1</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>9158</td>\n",
       "      <td>1</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.430783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4366</td>\n",
       "      <td>1</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>10558</td>\n",
       "      <td>5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>3580</td>\n",
       "      <td>5</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>9320</td>\n",
       "      <td>5</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.158461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3571</th>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>10390</td>\n",
       "      <td>5</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>2861</td>\n",
       "      <td>5</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adrd  treatment  patid  antiasthma  log_count         0    1         2  \\\n",
       "1398     0  treatment   4992           1   2.708050  0.000000  0.0  0.000000   \n",
       "5975     0  treatment   8502           1   1.609438  0.000000  0.0  1.098612   \n",
       "1425     0  treatment   2809           1   1.098612  0.000000  0.0  0.000000   \n",
       "1032     0  treatment   9158           1   3.737670  0.000000  0.0  0.000000   \n",
       "2443     0  treatment   4366           1   3.258097  0.000000  0.0  0.000000   \n",
       "...    ...        ...    ...         ...        ...       ...  ...       ...   \n",
       "4222     0    control  10558           5   0.693147  0.000000  0.0  0.000000   \n",
       "4803     0    control   3580           5   2.944439  0.000000  0.0  0.693147   \n",
       "5429     1    control   9320           5   4.077537  0.000000  0.0  1.098612   \n",
       "3571     1    control  10390           5   2.772589  1.386294  0.0  0.000000   \n",
       "4851     0    control   2861           5   1.945910  0.000000  0.0  0.000000   \n",
       "\n",
       "        3    4  ...  241   242  243  244  245  246  247  248     score  T  \n",
       "1398  0.0  0.0  ...  0.0  82.0  1.0  0.0  0.0  0.0  0.0  1.0  0.201304  1  \n",
       "5975  0.0  0.0  ...  0.0  76.0  0.0  0.0  0.0  0.0  0.0  1.0  0.274878  1  \n",
       "1425  0.0  0.0  ...  0.0  90.0  1.0  0.0  0.0  1.0  0.0  0.0  0.478050  1  \n",
       "1032  0.0  0.0  ...  0.0  89.0  1.0  0.0  0.0  0.0  0.0  1.0  0.430783  1  \n",
       "2443  0.0  0.0  ...  0.0  74.0  0.0  0.0  0.0  0.0  0.0  1.0  0.466876  1  \n",
       "...   ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  ...       ... ..  \n",
       "4222  0.0  0.0  ...  0.0  80.0  0.0  0.0  1.0  0.0  0.0  0.0  0.212148  0  \n",
       "4803  0.0  0.0  ...  0.0  76.0  1.0  0.0  1.0  0.0  0.0  0.0  0.302202  0  \n",
       "5429  0.0  0.0  ...  0.0  89.0  1.0  0.0  0.0  0.0  0.0  1.0  0.158461  0  \n",
       "3571  0.0  0.0  ...  0.0  88.0  1.0  0.0  1.0  0.0  0.0  0.0  0.302031  0  \n",
       "4851  0.0  0.0  ...  0.0  90.0  0.0  0.0  1.0  0.0  0.0  0.0  0.301613  0  \n",
       "\n",
       "[384 rows x 256 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(x_train0)\n",
    "score = xgb.predict_proba(x_train0)\n",
    "e = {t: score[0:l, t] for t in np.unique(treatment)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(e, open(save_path+'ps1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_s = BaseSClassifier(learner=LogisticRegression(max_iter=3000), control_name='control')\n",
    "learner_s.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5529\n",
      "INFO:causalml:     AUC (Treatment):     0.5408\n",
      "INFO:causalml:Log Loss   (Control):     0.3832\n",
      "INFO:causalml:Log Loss (Treatment):     0.4028\n",
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9443\n",
      "INFO:causalml:     AUC (Treatment):     0.9365\n",
      "INFO:causalml:Log Loss   (Control):     0.1873\n",
      "INFO:causalml:Log Loss (Treatment):     0.2046\n"
     ]
    }
   ],
   "source": [
    "cate_s = learner_s.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "test_learner_s = BaseSClassifier(learner=LogisticRegression(max_iter=3000), control_name='control')\n",
    "test_cate_s = test_learner_s.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'],\n",
    "                y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03615171232241213"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_s-test_cate_s)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.605520083955194e-05"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_s.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_srf = BaseSClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "learner_srf.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5316\n",
      "INFO:causalml:     AUC (Treatment):     0.5380\n",
      "INFO:causalml:Log Loss   (Control):     0.3713\n",
      "INFO:causalml:Log Loss (Treatment):     0.3882\n",
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9832\n",
      "INFO:causalml:     AUC (Treatment):     0.9797\n",
      "INFO:causalml:Log Loss   (Control):     0.2432\n",
      "INFO:causalml:Log Loss (Treatment):     0.2596\n"
     ]
    }
   ],
   "source": [
    "cate_srf = learner_srf.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "test_learner_srf = BaseSClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "test_cate_srf = test_learner_srf.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026899213676390664"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_srf-test_cate_srf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0918430505870655e-07"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_srf.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0084\n",
      "INFO:causalml:Log Loss (Treatment):     0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01773468584328339"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_sxg = BaseSClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "learner_sxg.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_sxg = learner_sxg.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_sxg = BaseSClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "test_cate_sxg = test_learner_sxg.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_sxg-test_cate_sxg)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_t = BaseTClassifier(learner = LogisticRegression(max_iter = 3000), control_name='control')\n",
    "learner_t.fit(X=x_train0, treatment=df_train0['treatment'], y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5400\n",
      "INFO:causalml:     AUC (Treatment):     0.5475\n",
      "INFO:causalml:Log Loss   (Control):     0.3939\n",
      "INFO:causalml:Log Loss (Treatment):     0.5024\n"
     ]
    }
   ],
   "source": [
    "cate_t = learner_t.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9636\n",
      "INFO:causalml:     AUC (Treatment):     0.9992\n",
      "INFO:causalml:Log Loss   (Control):     0.1602\n",
      "INFO:causalml:Log Loss (Treatment):     0.0691\n"
     ]
    }
   ],
   "source": [
    "test_learner_t = BaseTClassifier(learner = LogisticRegression(max_iter = 3000), control_name='control')\n",
    "test_cate_t = test_learner_t.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3105545486061205"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_t-test_cate_t)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9861\n",
      "INFO:causalml:     AUC (Treatment):     0.9965\n",
      "INFO:causalml:Log Loss   (Control):     0.2268\n",
      "INFO:causalml:Log Loss (Treatment):     0.2135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07343445152391198"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_trf = BaseTClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "learner_trf.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_trf = learner_trf.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_trf = BaseTClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "test_cate_trf = test_learner_trf.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_trf-test_cate_trf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0069\n",
      "INFO:causalml:Log Loss (Treatment):     0.0094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2959846988196666"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_txg = BaseTClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "learner_txg.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_txg = learner_txg.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_txg = BaseTClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "test_cate_txg = test_learner_txg.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_txg-test_cate_txg)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(x_train0)\n",
    "score = xgb.predict_proba(x_train0)\n",
    "e = {t: score[0:l, t] for t in np.unique(treatment)}\n",
    "\n",
    "l_test = len(x_test0)\n",
    "score_test = xgb.predict_proba(x_test0)\n",
    "e_test = {t: score[0:l_test, t] for t in np.unique(treatment_test)}\n",
    "\n",
    "treatment = np.array(treatment)\n",
    "treatment_test = np.array(treatment_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     0.9636\n",
      "INFO:causalml:     AUC (Treatment):     0.9992\n",
      "INFO:causalml:Log Loss   (Control):     0.1602\n",
      "INFO:causalml:Log Loss (Treatment):     0.0691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07263506576962021"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_x = BaseXClassifier(outcome_learner=LogisticRegression(max_iter=3000),\n",
    "                            effect_learner=ElasticNetCV(max_iter=3000, random_state=1105))\n",
    "learner_x.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_x = learner_x.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_x = BaseXClassifier(outcome_learner=LogisticRegression(max_iter=3000), \n",
    "                                 effect_learner=ElasticNetCV(max_iter=3000, random_state=1105))\n",
    "test_cate_x = test_learner_x.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_x-test_cate_x)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     0.9861\n",
      "INFO:causalml:     AUC (Treatment):     0.9965\n",
      "INFO:causalml:Log Loss   (Control):     0.2268\n",
      "INFO:causalml:Log Loss (Treatment):     0.2135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11825156610781064"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_xrf = BaseXClassifier(outcome_learner=RandomForestClassifier(random_state=1105, max_depth=6),\n",
    "                            effect_learner=RandomForestRegressor(random_state=1105, max_depth=6))\n",
    "learner_xrf.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_xrf = learner_xrf.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_xrf = BaseXClassifier(outcome_learner=RandomForestClassifier(random_state=1105, max_depth=6), \n",
    "                                 effect_learner=RandomForestRegressor(random_state=1105, max_depth=6))\n",
    "test_cate_xrf = test_learner_xrf.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_xrf-test_cate_xrf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0069\n",
      "INFO:causalml:Log Loss (Treatment):     0.0094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24008614713283347"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_xgb = BaseXClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=6, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=6))\n",
    "learner_xgb.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_xgb = learner_xgb.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_xgb = BaseXClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=6, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=6))\n",
    "test_cate_xgb = test_learner_xgb.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_xgb-test_cate_xgb)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n",
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.025739212088139545"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_r = BaseRClassifier(outcome_learner=LogisticRegression(max_iter=3000),\n",
    "                            effect_learner=ElasticNet(max_iter=3000, random_state=1105))\n",
    "learner_r.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_r = learner_r.predict(X=x_test0, p=e_test)\n",
    "test_learner_r = BaseRClassifier(outcome_learner=LogisticRegression(max_iter=3000), \n",
    "                                 effect_learner=ElasticNet(max_iter=3000, random_state=1105))\n",
    "test_cate_r = test_learner_r.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_r-test_cate_r)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train0)\n",
    "x_test = np.array(x_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n",
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.621283903414356"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_rgb = BaseRClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=5, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=5))\n",
    "learner_rgb.fit(X=x_train, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_rgb = learner_rgb.predict(X=x_test, p=e_test)\n",
    "test_learner_rgb = BaseRClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=5, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=5))\n",
    "test_cate_rgb = test_learner_rgb.fit_predict(X=x_test, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_rgb-test_cate_rgb)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [cate_srf.flatten(), cate_trf.flatten(), cate_xrf.flatten()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe4476c1890>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(-0.2, 0.2, 10)\n",
    "plt.hist(data1, bins, label = ['S-RF', 'T-RF', 'X-RF'])\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use influence function to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug-in section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cate_validation import influence_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_plugin1 = XGBClassifier(max_depth=6, random_state=1105, n_estimators=100)\n",
    "xgb_plugin0 = XGBClassifier(max_depth=6, random_state=1108, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_val0['adrd']\n",
    "l_val = len(x_val0)\n",
    "score = xgb.predict_proba(x_val0)\n",
    "e_val = {t: score[0:l_val, t] for t in np.unique(treatment_val)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = df_train0.loc[df_train0['treatment'] == 'control', 0:248]\n",
    "y0 = df_train0.loc[df_train0['treatment'] == 'control', 'adrd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              random_state=1108, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_plugin0.fit(x0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df_train0.loc[df_train0['treatment'] == 'treatment', 0:248]\n",
    "y1 = df_train0.loc[df_train0['treatment'] == 'treatment', 'adrd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              random_state=1105, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_plugin1.fit(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = xgb_plugin0.predict(x_val0)\n",
    "y_pred1 = xgb_plugin1.predict(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_plugin = y_pred1 - y_pred0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unplugged validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_x = learner_trf.predict(X=x_val0, treatment=treatment_val, p=e_val)\n",
    "cate = cate_x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug_in = (t_plugin-cate)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = xgb.predict_proba(x_val0)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (treatment_val - ps)\n",
    "ident = np.array([1]*len(ps))\n",
    "c = (ps*(ident-ps))\n",
    "b = np.array([2]*len(treatment_val))*treatment_val*(treatment_val-ps) / c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_de = (ident - b) * t_plugin**2 + b*y_val*(t_plugin - cate) + (- a*(t_plugin - cate)**2 + cate**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.429972475252534"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(l_de) + np.sum(plug_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_x = learner_xrf.predict(X=x_val0, treatment=treatment_val, p=e_val)\n",
    "cate = cate_x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug_in = (t_plugin-cate)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (treatment_val - ps)\n",
    "ident = np.array([1]*len(ps))\n",
    "c = (ps*(ident-ps))\n",
    "b = np.array([2]*len(treatment_val))*treatment_val*(treatment_val-ps) / c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_de = (ident - b) * t_plugin**2 + b*y_val*(t_plugin - cate) + (- a*(t_plugin - cate)**2 + cate**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.979020950216544"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(l_de) + np.sum(plug_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_x = learner_x.predict(X=x_val0, treatment=treatment_val, p=e_val)\n",
    "cate = cate_x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug_in = (t_plugin-cate)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (treatment_val - ps)\n",
    "ident = np.array([1]*len(ps))\n",
    "c = (ps*(ident-ps))\n",
    "b = np.array([2]*len(treatment_val))*treatment_val*(treatment_val-ps) / c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_de = (ident - b) * t_plugin**2 + b*y_val*(t_plugin - cate) + (- a*(t_plugin - cate)**2 + cate**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.947409855550774"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(l_de) + np.sum(plug_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_x = learner_r.predict(X=x_val0, p=e_val)\n",
    "cate = cate_x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug_in = (t_plugin-cate)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (treatment_val - ps)\n",
    "ident = np.array([1]*len(ps))\n",
    "c = (ps*(ident-ps))\n",
    "b = np.array([2]*len(treatment_val))*treatment_val*(treatment_val-ps) / c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_de = (ident - b) * t_plugin**2 + b*y_val*(t_plugin - cate)+ (- a*(t_plugin - cate)**2 + cate**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.597745679871803"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(l_de) + np.sum(plug_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-yling] *",
   "language": "python",
   "name": "conda-env-.conda-yling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
