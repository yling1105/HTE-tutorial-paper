{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV, MultiTaskElasticNetCV, ElasticNetCV, LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('causalml')\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='../Processed/final/'\n",
    "save_path='../Processed/final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_train, T_train, X_train, W_train)=pickle.load(open(data_path+'YTXW_train.pkl','rb'))\n",
    "(Y_test, T_test, X_test, W_test)=pickle.load(open(data_path+'YTXW_test.pkl','rb'))\n",
    "(Y_val, T_val, X_val, W_val)=pickle.load(open(data_path+'YTXW_val.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dx=pickle.load(open(data_path+'le_dx.pkl','rb'))\n",
    "le_patid=pickle.load(open(data_path+'le_patid.pkl','rb'))\n",
    "selected_patient_feature=['age_onset','obs_win','female']+['race__'+c for c in ['A','B','H','U','W']]\n",
    "rx2id = pickle.load(open(data_path+'drug_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Y,T,W,X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several steps:\n",
    "- Standardize age\n",
    "- Combine demographics with dx information \n",
    "- Set treatment and control group\n",
    "- Output a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def prepare(y, t, w, x, rx2id, target):\n",
    "    patid_temp = list(w['patid'].unique())\n",
    "    temp_le = preprocessing.LabelEncoder()\n",
    "    temp_le.fit(list(patid_temp))\n",
    "    w['row_idx'] = temp_le.transform(w['patid'])\n",
    "    \n",
    "    w_sparse = csr_matrix((w['log_count'], (w['row_idx'], w['phecode3'])))\n",
    "    w = w_sparse.toarray()\n",
    "    \n",
    "    x_temp = np.concatenate((w, x.values), axis=1)\n",
    "    \n",
    "    treatment_train = [0] * len(t)\n",
    "    temp_index = t.index\n",
    "    idx = 0\n",
    "\n",
    "    def get_classes(value):\n",
    "        return [k for k, v in rx2id.items() if v == value]\n",
    "\n",
    "    for i in temp_index:\n",
    "        classes = t.loc[i, 'antiasthma']\n",
    "        if (classes != target):\n",
    "            treatment_train[idx] = 'control'\n",
    "        else:\n",
    "            treatment_train[idx] = 'treatment'\n",
    "        idx += 1\n",
    "        \n",
    "    treatment = pd.DataFrame(treatment_train)\n",
    "    treatment.index = temp_index\n",
    "    treatment.columns = ['treatment']\n",
    "    \n",
    "    y = pd.DataFrame(y)\n",
    "    feature_df = pd.DataFrame(x_temp)\n",
    "    feature_df.index = y.index\n",
    "    \n",
    "    df = pd.concat([y, treatment, t, feature_df], axis=1)\n",
    "    df.index = np.arange(0, len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark (Corticosteroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 2\n",
    "df_val0 = prepare(Y_val, T_val, W_val, X_val, rx2id, target)\n",
    "df_test0 = prepare(Y_test, T_test, W_test, X_test, rx2id, target)\n",
    "df_train0 = prepare(Y_train, T_train, W_train, X_train, rx2id, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0 = df_train0.iloc[:, 5:]\n",
    "x_test0 = df_test0.iloc[:, 5:]\n",
    "x_val0 = df_val0.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, BaseSRegressor, BaseTRegressor\n",
    "from causalml.metrics import plot_gain, auuc_score\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from causalml.inference.meta import BaseSClassifier, BaseTClassifier, BaseXClassifier, BaseRClassifier\n",
    "from causalml.feature_selection.filters import FilterSelect\n",
    "\n",
    "from causalml.propensity import GradientBoostedPropensityModel\n",
    "from causalml.propensity import compute_propensity_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_train0['treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = [0] * len(t)\n",
    "for i in range(len(t)):\n",
    "    if t[i] == 'control':\n",
    "        treatment[i] = 0\n",
    "    else:\n",
    "        treatment[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = df_test0['treatment']\n",
    "treatment_test = [0] * len(t_test)\n",
    "for i in range(len(t_test)):\n",
    "    if t_test[i] == 'control':\n",
    "        treatment_test[i] = 0\n",
    "    else:\n",
    "        treatment_test[i] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val = df_val0['treatment']\n",
    "treatment_val = [0] * len(t_val)\n",
    "for i in range(len(t_val)):\n",
    "    if t_val[i] == 'control':\n",
    "        treatment_val[i] = 0\n",
    "    else:\n",
    "        treatment_val[i] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=3000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm = LogisticRegression(max_iter = 3000)\n",
    "glm.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred_p = glm.predict_proba(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = t_pred_p[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20028413, 0.2279316 , 0.10219598, ..., 0.18590268, 0.19473148,\n",
       "       0.13565735])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5282658988608646"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, random_state=1105)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=6, random_state=1105)\n",
    "rf.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5806629868986848"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = rf.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              random_state=1105, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, random_state=1105, n_estimators=100)\n",
    "xgb.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5168192219679634"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = xgb.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(max_depth = 6, random_state = 1105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=6, random_state=1105)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5330506450071668"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = gbc.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(l1_ratio=0.1, max_iter=3000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_l1 = LogisticRegression(penalty='elasticnet', max_iter = 3000, solver='saga', l1_ratio=0.1)\n",
    "glm_l1.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred_p = glm_l1.predict_proba(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = t_pred_p[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5280031181633013"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = xgb.predict_proba(x_train0)[:, 1]\n",
    "df_train0['score'] = score\n",
    "df_train0['T'] = treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = list(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adrd</th>\n",
       "      <th>treatment</th>\n",
       "      <th>patid</th>\n",
       "      <th>antiasthma</th>\n",
       "      <th>log_count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>score</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>9722</td>\n",
       "      <td>1</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1232</td>\n",
       "      <td>5</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>2220</td>\n",
       "      <td>1</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1806</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>9768</td>\n",
       "      <td>2</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>9185</td>\n",
       "      <td>3</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.184156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>9752</td>\n",
       "      <td>1</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.135903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>3868</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>6972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.149031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>4886</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6771 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adrd  treatment  patid  antiasthma  log_count    0         1         2  \\\n",
       "0        0    control   9722           1   1.945910  0.0  0.000000  0.000000   \n",
       "1        0    control   1232           5   1.386294  0.0  0.000000  1.098612   \n",
       "2        0    control   2220           1   3.583519  0.0  0.000000  0.000000   \n",
       "3        0    control   1806           4   0.693147  0.0  0.000000  0.000000   \n",
       "4        0  treatment   9768           2   1.386294  0.0  0.000000  0.000000   \n",
       "...    ...        ...    ...         ...        ...  ...       ...       ...   \n",
       "6766     0    control   9185           3   3.044522  0.0  0.000000  0.000000   \n",
       "6767     1    control   9752           1   1.609438  0.0  0.000000  0.693147   \n",
       "6768     0    control   3868           1   0.693147  0.0  0.000000  0.693147   \n",
       "6769     0    control   6972           1   0.693147  0.0  0.000000  0.693147   \n",
       "6770     0    control   4886           4   0.693147  0.0  0.693147  0.000000   \n",
       "\n",
       "             3         4  ...  241   242  243  244  245  246  247  248  \\\n",
       "0     0.000000  0.000000  ...  0.0  75.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1     1.098612  0.693147  ...  0.0  72.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2     0.000000  0.000000  ...  0.0  74.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3     0.000000  0.000000  ...  0.0  83.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "4     0.000000  0.000000  ...  0.0  84.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "...        ...       ...  ...  ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "6766  0.000000  0.000000  ...  0.0  90.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6767  0.000000  0.000000  ...  0.0  83.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6768  0.000000  0.000000  ...  0.0  88.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "6769  0.000000  0.000000  ...  0.0  89.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6770  1.098612  0.000000  ...  0.0  83.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "         score  T  \n",
       "0     0.057919  0  \n",
       "1     0.046936  0  \n",
       "2     0.029653  0  \n",
       "3     0.029765  0  \n",
       "4     0.832310  1  \n",
       "...        ... ..  \n",
       "6766  0.184156  0  \n",
       "6767  0.135903  0  \n",
       "6768  0.027778  0  \n",
       "6769  0.149031  0  \n",
       "6770  0.029447  0  \n",
       "\n",
       "[6771 rows x 256 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.match import NearestNeighborMatch, create_table_one\n",
    "\n",
    "psm = NearestNeighborMatch(replace=False,\n",
    "                           ratio=1,\n",
    "                           random_state=42)\n",
    "\n",
    "matched = psm.match(data=df_train0,\n",
    "                    treatment_col='T',\n",
    "                    score_cols=['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1429"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adrd</th>\n",
       "      <th>treatment</th>\n",
       "      <th>patid</th>\n",
       "      <th>antiasthma</th>\n",
       "      <th>log_count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>score</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>7829</td>\n",
       "      <td>2</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.429981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>9134</td>\n",
       "      <td>2</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.471600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2117</td>\n",
       "      <td>2</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.463985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>6054</td>\n",
       "      <td>2</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.405361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>4604</td>\n",
       "      <td>3</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.278200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1835</td>\n",
       "      <td>5</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.266883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>2292</td>\n",
       "      <td>4</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.268328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>8511</td>\n",
       "      <td>5</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.240926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.276285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adrd  treatment  patid  antiasthma  log_count         0    1         2  \\\n",
       "2544     0  treatment   7829           2   1.098612  0.000000  0.0  0.000000   \n",
       "4678     0  treatment   9134           2   1.791759  0.000000  0.0  1.098612   \n",
       "5029     0  treatment    123           2   1.945910  0.000000  0.0  0.000000   \n",
       "6197     0  treatment   2117           2   3.401197  0.000000  0.0  0.693147   \n",
       "5714     0  treatment   6054           2   3.295837  0.693147  0.0  0.000000   \n",
       "...    ...        ...    ...         ...        ...       ...  ...       ...   \n",
       "1455     0    control   4604           3   2.397895  0.000000  0.0  0.000000   \n",
       "5560     0    control   1835           5   3.912023  0.000000  0.0  0.000000   \n",
       "2961     0    control   2292           4   2.197225  0.000000  0.0  0.000000   \n",
       "1163     0    control   8511           5   3.465736  0.000000  0.0  0.000000   \n",
       "2121     0    control    542           1   2.197225  0.000000  0.0  0.000000   \n",
       "\n",
       "        3    4  ...  241   242  243  244  245  246  247  248     score  T  \n",
       "2544  0.0  0.0  ...  0.0  84.0  1.0  0.0  0.0  0.0  0.0  1.0  0.429981  1  \n",
       "4678  0.0  0.0  ...  0.0  81.0  0.0  0.0  0.0  0.0  0.0  1.0  0.361935  1  \n",
       "5029  0.0  0.0  ...  0.0  86.0  0.0  0.0  0.0  0.0  0.0  1.0  0.471600  1  \n",
       "6197  0.0  0.0  ...  0.0  82.0  0.0  0.0  0.0  0.0  0.0  1.0  0.463985  1  \n",
       "5714  0.0  0.0  ...  0.0  82.0  1.0  0.0  0.0  0.0  0.0  1.0  0.405361  1  \n",
       "...   ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  ...       ... ..  \n",
       "1455  0.0  0.0  ...  0.0  82.0  0.0  0.0  0.0  0.0  0.0  1.0  0.278200  0  \n",
       "5560  0.0  0.0  ...  0.0  84.0  1.0  0.0  0.0  0.0  0.0  1.0  0.266883  0  \n",
       "2961  0.0  0.0  ...  0.0  85.0  0.0  0.0  0.0  0.0  0.0  1.0  0.268328  0  \n",
       "1163  0.0  0.0  ...  0.0  79.0  0.0  0.0  0.0  0.0  0.0  1.0  0.240926  0  \n",
       "2121  0.0  0.0  ...  0.0  78.0  1.0  0.0  0.0  0.0  0.0  1.0  0.276285  0  \n",
       "\n",
       "[236 rows x 256 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(x_train0)\n",
    "score = xgb.predict_proba(x_train0)\n",
    "e = {t: score[0:l, t] for t in np.unique(treatment)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(e, open(save_path+'ps1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_s = BaseSClassifier(learner=LogisticRegression(max_iter=3000), control_name='control')\n",
    "learner_s.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5467\n",
      "INFO:causalml:     AUC (Treatment):     0.5564\n",
      "INFO:causalml:Log Loss   (Control):     0.3840\n",
      "INFO:causalml:Log Loss (Treatment):     0.4042\n",
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9360\n",
      "INFO:causalml:     AUC (Treatment):     0.9621\n",
      "INFO:causalml:Log Loss   (Control):     0.1988\n",
      "INFO:causalml:Log Loss (Treatment):     0.1666\n"
     ]
    }
   ],
   "source": [
    "cate_s = learner_s.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "test_learner_s = BaseSClassifier(learner=LogisticRegression(max_iter=3000), control_name='control')\n",
    "test_cate_s = test_learner_s.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'],\n",
    "                y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03389594057488274"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_s-test_cate_s)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013800014240620873"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_s.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_srf = BaseSClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "learner_srf.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5301\n",
      "INFO:causalml:     AUC (Treatment):     0.5376\n",
      "INFO:causalml:Log Loss   (Control):     0.3722\n",
      "INFO:causalml:Log Loss (Treatment):     0.3889\n",
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9803\n",
      "INFO:causalml:     AUC (Treatment):     0.9910\n",
      "INFO:causalml:Log Loss   (Control):     0.2480\n",
      "INFO:causalml:Log Loss (Treatment):     0.2447\n"
     ]
    }
   ],
   "source": [
    "cate_srf = learner_srf.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "test_learner_srf = BaseSClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "test_cate_srf = test_learner_srf.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00394925909970949"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_srf-test_cate_srf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.661539388216228e-06"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_srf.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0085\n",
      "INFO:causalml:Log Loss (Treatment):     0.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.033250255846374664"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_sxg = BaseSClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "learner_sxg.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_sxg = learner_sxg.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_sxg = BaseSClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "test_cate_sxg = test_learner_sxg.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_sxg-test_cate_sxg)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_t = BaseTClassifier(learner = LogisticRegression(max_iter = 3000), control_name='control')\n",
    "learner_t.fit(X=x_train0, treatment=df_train0['treatment'], y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5404\n",
      "INFO:causalml:     AUC (Treatment):     0.5455\n",
      "INFO:causalml:Log Loss   (Control):     0.3897\n",
      "INFO:causalml:Log Loss (Treatment):     0.5365\n"
     ]
    }
   ],
   "source": [
    "cate_t = learner_t.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9539\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.1750\n",
      "INFO:causalml:Log Loss (Treatment):     0.0408\n"
     ]
    }
   ],
   "source": [
    "test_learner_t = BaseTClassifier(learner = LogisticRegression(max_iter = 3000), control_name='control')\n",
    "test_cate_t = test_learner_t.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31854566903658305"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_t-test_cate_t)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9836\n",
      "INFO:causalml:     AUC (Treatment):     0.9990\n",
      "INFO:causalml:Log Loss   (Control):     0.2385\n",
      "INFO:causalml:Log Loss (Treatment):     0.1907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07354558674729829"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_trf = BaseTClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "learner_trf.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_trf = learner_trf.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_trf = BaseTClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "test_cate_trf = test_learner_trf.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_trf-test_cate_trf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0078\n",
      "INFO:causalml:Log Loss (Treatment):     0.0084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2943347695699526"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_txg = BaseTClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "learner_txg.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_txg = learner_txg.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_txg = BaseTClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "test_cate_txg = test_learner_txg.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_txg-test_cate_txg)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(x_train0)\n",
    "score = xgb.predict_proba(x_train0)\n",
    "e = {t: score[0:l, t] for t in np.unique(treatment)}\n",
    "\n",
    "l_test = len(x_test0)\n",
    "score_test = xgb.predict_proba(x_test0)\n",
    "e_test = {t: score[0:l_test, t] for t in np.unique(treatment_test)}\n",
    "\n",
    "treatment = np.array(treatment)\n",
    "treatment_test = np.array(treatment_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     0.9539\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.1750\n",
      "INFO:causalml:Log Loss (Treatment):     0.0408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08697803942544616"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_x = BaseXClassifier(outcome_learner=LogisticRegression(max_iter=3000),\n",
    "                            effect_learner=ElasticNetCV(max_iter=3000, random_state=1105))\n",
    "learner_x.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_x = learner_x.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_x = BaseXClassifier(outcome_learner=LogisticRegression(max_iter=3000), \n",
    "                                 effect_learner=ElasticNetCV(max_iter=3000, random_state=1105))\n",
    "test_cate_x = test_learner_x.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_x-test_cate_x)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     0.9836\n",
      "INFO:causalml:     AUC (Treatment):     0.9990\n",
      "INFO:causalml:Log Loss   (Control):     0.2385\n",
      "INFO:causalml:Log Loss (Treatment):     0.1907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13866773497311646"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_xrf = BaseXClassifier(outcome_learner=RandomForestClassifier(random_state=1105, max_depth=6),\n",
    "                            effect_learner=RandomForestRegressor(random_state=1105, max_depth=6))\n",
    "learner_xrf.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_xrf = learner_xrf.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_xrf = BaseXClassifier(outcome_learner=RandomForestClassifier(random_state=1105, max_depth=6), \n",
    "                                 effect_learner=RandomForestRegressor(random_state=1105, max_depth=6))\n",
    "test_cate_xrf = test_learner_xrf.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_xrf-test_cate_xrf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0078\n",
      "INFO:causalml:Log Loss (Treatment):     0.0084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24564935459429602"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_xgb = BaseXClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=6, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=6))\n",
    "learner_xgb.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_xgb = learner_xgb.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_xgb = BaseXClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=6, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=6))\n",
    "test_cate_xgb = test_learner_xgb.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_xgb-test_cate_xgb)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n",
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05507637506467934"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_r = BaseRClassifier(outcome_learner=LogisticRegression(max_iter=3000),\n",
    "                            effect_learner=ElasticNet(max_iter=3000, random_state=1105))\n",
    "learner_r.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_r = learner_r.predict(X=x_test0, p=e_test)\n",
    "test_learner_r = BaseRClassifier(outcome_learner=LogisticRegression(max_iter=3000), \n",
    "                                 effect_learner=ElasticNet(max_iter=3000, random_state=1105))\n",
    "test_cate_r = test_learner_r.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_r-test_cate_r)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train0)\n",
    "x_test = np.array(x_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n",
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6723349232291267"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_rgb = BaseRClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=5, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=5))\n",
    "learner_rgb.fit(X=x_train, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_rgb = learner_rgb.predict(X=x_test, p=e_test)\n",
    "test_learner_rgb = BaseRClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=5, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=5))\n",
    "test_cate_rgb = test_learner_rgb.fit_predict(X=x_test, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_rgb-test_cate_rgb)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [cate_srf.flatten(), cate_trf.flatten(), cate_xrf.flatten()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9a704a4c50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(-0.2, 0.2, 10)\n",
    "plt.hist(data1, bins, label = ['S-RF', 'T-RF', 'X-RF'])\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-yling] *",
   "language": "python",
   "name": "conda-env-.conda-yling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
