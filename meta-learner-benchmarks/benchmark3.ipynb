{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV, MultiTaskElasticNetCV, ElasticNetCV, LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('causalml')\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='../Processed/final/'\n",
    "save_path='../Processed/final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_train, T_train, X_train, W_train)=pickle.load(open(data_path+'YTXW_train.pkl','rb'))\n",
    "(Y_test, T_test, X_test, W_test)=pickle.load(open(data_path+'YTXW_test.pkl','rb'))\n",
    "(Y_val, T_val, X_val, W_val)=pickle.load(open(data_path+'YTXW_val.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dx=pickle.load(open(data_path+'le_dx.pkl','rb'))\n",
    "le_patid=pickle.load(open(data_path+'le_patid.pkl','rb'))\n",
    "selected_patient_feature=['age_onset','obs_win','female']+['race__'+c for c in ['A','B','H','U','W']]\n",
    "rx2id = pickle.load(open(data_path+'drug_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Y,T,W,X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several steps:\n",
    "- Standardize age\n",
    "- Combine demographics with dx information \n",
    "- Set treatment and control group\n",
    "- Output a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def prepare(y, t, w, x, rx2id, target):\n",
    "    patid_temp = list(w['patid'].unique())\n",
    "    temp_le = preprocessing.LabelEncoder()\n",
    "    temp_le.fit(list(patid_temp))\n",
    "    w['row_idx'] = temp_le.transform(w['patid'])\n",
    "    \n",
    "    w_sparse = csr_matrix((w['log_count'], (w['row_idx'], w['phecode3'])))\n",
    "    w = w_sparse.toarray()\n",
    "    \n",
    "    x_temp = np.concatenate((w, x.values), axis=1)\n",
    "    \n",
    "    treatment_train = [0] * len(t)\n",
    "    temp_index = t.index\n",
    "    idx = 0\n",
    "\n",
    "    def get_classes(value):\n",
    "        return [k for k, v in rx2id.items() if v == value]\n",
    "\n",
    "    for i in temp_index:\n",
    "        classes = t.loc[i, 'antiasthma']\n",
    "        if (classes != target):\n",
    "            treatment_train[idx] = 'control'\n",
    "        else:\n",
    "            treatment_train[idx] = 'treatment'\n",
    "        idx += 1\n",
    "        \n",
    "    treatment = pd.DataFrame(treatment_train)\n",
    "    treatment.index = temp_index\n",
    "    treatment.columns = ['treatment']\n",
    "    \n",
    "    y = pd.DataFrame(y)\n",
    "    feature_df = pd.DataFrame(x_temp)\n",
    "    feature_df.index = y.index\n",
    "    \n",
    "    df = pd.concat([y, treatment, t, feature_df], axis=1)\n",
    "    df.index = np.arange(0, len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark (Agonist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 3\n",
    "df_val0 = prepare(Y_val, T_val, W_val, X_val, rx2id, target)\n",
    "df_test0 = prepare(Y_test, T_test, W_test, X_test, rx2id, target)\n",
    "df_train0 = prepare(Y_train, T_train, W_train, X_train, rx2id, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0 = df_train0.iloc[:, 5:]\n",
    "x_test0 = df_test0.iloc[:, 5:]\n",
    "x_val0 = df_val0.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, BaseSRegressor, BaseTRegressor\n",
    "from causalml.metrics import plot_gain, auuc_score\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from causalml.inference.meta import BaseSClassifier, BaseTClassifier, BaseXClassifier, BaseRClassifier\n",
    "from causalml.feature_selection.filters import FilterSelect\n",
    "\n",
    "from causalml.propensity import GradientBoostedPropensityModel\n",
    "from causalml.propensity import compute_propensity_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_train0['treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = [0] * len(t)\n",
    "for i in range(len(t)):\n",
    "    if t[i] == 'control':\n",
    "        treatment[i] = 0\n",
    "    else:\n",
    "        treatment[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = df_test0['treatment']\n",
    "treatment_test = [0] * len(t_test)\n",
    "for i in range(len(t_test)):\n",
    "    if t_test[i] == 'control':\n",
    "        treatment_test[i] = 0\n",
    "    else:\n",
    "        treatment_test[i] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val = df_val0['treatment']\n",
    "treatment_val = [0] * len(t_val)\n",
    "for i in range(len(t_val)):\n",
    "    if t_val[i] == 'control':\n",
    "        treatment_val[i] = 0\n",
    "    else:\n",
    "        treatment_val[i] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=3000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm = LogisticRegression(max_iter = 3000)\n",
    "glm.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred_p = glm.predict_proba(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = t_pred_p[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18635337, 0.05122293, 0.32046067, ..., 0.23346986, 0.1820708 ,\n",
       "       0.29586571])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5786797702999468"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, random_state=1105)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=6, random_state=1105)\n",
    "rf.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5808019496314887"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = rf.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              random_state=1105, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, random_state=1105, n_estimators=100)\n",
    "xgb.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5457808756064181"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = xgb.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(max_depth = 6, random_state = 1105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=6, random_state=1105)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5565395405089593"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = gbc.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(l1_ratio=0.1, max_iter=3000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_l1 = LogisticRegression(penalty='elasticnet', max_iter = 3000, solver='saga', l1_ratio=0.1)\n",
    "glm_l1.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred_p = glm_l1.predict_proba(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = t_pred_p[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5728861184237448"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = xgb.predict_proba(x_train0)[:, 1]\n",
    "df_train0['score'] = score\n",
    "df_train0['T'] = treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = list(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adrd</th>\n",
       "      <th>treatment</th>\n",
       "      <th>patid</th>\n",
       "      <th>antiasthma</th>\n",
       "      <th>log_count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>score</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>9722</td>\n",
       "      <td>1</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1232</td>\n",
       "      <td>5</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>2220</td>\n",
       "      <td>1</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1806</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>9768</td>\n",
       "      <td>2</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.207701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>9185</td>\n",
       "      <td>3</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>9752</td>\n",
       "      <td>1</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.054388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>3868</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>6972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.307831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>4886</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6771 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adrd  treatment  patid  antiasthma  log_count    0         1         2  \\\n",
       "0        0    control   9722           1   1.945910  0.0  0.000000  0.000000   \n",
       "1        0    control   1232           5   1.386294  0.0  0.000000  1.098612   \n",
       "2        0    control   2220           1   3.583519  0.0  0.000000  0.000000   \n",
       "3        0    control   1806           4   0.693147  0.0  0.000000  0.000000   \n",
       "4        0    control   9768           2   1.386294  0.0  0.000000  0.000000   \n",
       "...    ...        ...    ...         ...        ...  ...       ...       ...   \n",
       "6766     0  treatment   9185           3   3.044522  0.0  0.000000  0.000000   \n",
       "6767     1    control   9752           1   1.609438  0.0  0.000000  0.693147   \n",
       "6768     0    control   3868           1   0.693147  0.0  0.000000  0.693147   \n",
       "6769     0    control   6972           1   0.693147  0.0  0.000000  0.693147   \n",
       "6770     0    control   4886           4   0.693147  0.0  0.693147  0.000000   \n",
       "\n",
       "             3         4  ...  241   242  243  244  245  246  247  248  \\\n",
       "0     0.000000  0.000000  ...  0.0  75.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1     1.098612  0.693147  ...  0.0  72.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2     0.000000  0.000000  ...  0.0  74.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3     0.000000  0.000000  ...  0.0  83.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "4     0.000000  0.000000  ...  0.0  84.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "...        ...       ...  ...  ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "6766  0.000000  0.000000  ...  0.0  90.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6767  0.000000  0.000000  ...  0.0  83.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6768  0.000000  0.000000  ...  0.0  88.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "6769  0.000000  0.000000  ...  0.0  89.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6770  1.098612  0.000000  ...  0.0  83.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "         score  T  \n",
       "0     0.012743  0  \n",
       "1     0.027894  0  \n",
       "2     0.027349  0  \n",
       "3     0.020383  0  \n",
       "4     0.207701  0  \n",
       "...        ... ..  \n",
       "6766  0.320581  1  \n",
       "6767  0.054388  0  \n",
       "6768  0.141978  0  \n",
       "6769  0.307831  0  \n",
       "6770  0.035058  0  \n",
       "\n",
       "[6771 rows x 256 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.match import NearestNeighborMatch, create_table_one\n",
    "\n",
    "psm = NearestNeighborMatch(replace=False,\n",
    "                           ratio=1,\n",
    "                           random_state=42)\n",
    "\n",
    "matched = psm.match(data=df_train0,\n",
    "                    treatment_col='T',\n",
    "                    score_cols=['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adrd</th>\n",
       "      <th>treatment</th>\n",
       "      <th>patid</th>\n",
       "      <th>antiasthma</th>\n",
       "      <th>log_count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>score</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>9616</td>\n",
       "      <td>3</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.262922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>9185</td>\n",
       "      <td>3</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6764</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>7132</td>\n",
       "      <td>3</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.429594</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>3009</td>\n",
       "      <td>3</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>7969</td>\n",
       "      <td>3</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>10795</td>\n",
       "      <td>5</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.110809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1805</td>\n",
       "      <td>1</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.311202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1297</td>\n",
       "      <td>2</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.311178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>6882</td>\n",
       "      <td>1</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.308330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>10918</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adrd  treatment  patid  antiasthma  log_count    0         1    2    3  \\\n",
       "1052     0  treatment   9616           3   0.693147  0.0  0.000000  0.0  0.0   \n",
       "6766     0  treatment   9185           3   3.044522  0.0  0.000000  0.0  0.0   \n",
       "6764     0  treatment   7132           3   2.302585  0.0  0.000000  0.0  0.0   \n",
       "4874     0  treatment   3009           3   2.639057  0.0  0.000000  0.0  0.0   \n",
       "6530     0  treatment   7969           3   2.397895  0.0  0.000000  0.0  0.0   \n",
       "...    ...        ...    ...         ...        ...  ...       ...  ...  ...   \n",
       "6671     0    control  10795           5   2.772589  0.0  0.693147  0.0  0.0   \n",
       "2335     0    control   1805           1   3.332205  0.0  0.000000  0.0  0.0   \n",
       "4643     0    control   1297           2   2.079442  0.0  0.000000  0.0  0.0   \n",
       "2102     0    control   6882           1   2.944439  0.0  0.000000  0.0  0.0   \n",
       "6543     0    control  10918           1   0.693147  0.0  0.000000  0.0  0.0   \n",
       "\n",
       "        4  ...  241   242  243  244  245  246  247  248     score  T  \n",
       "1052  0.0  ...  0.0  81.0  1.0  0.0  0.0  0.0  0.0  1.0  0.262922  1  \n",
       "6766  0.0  ...  0.0  90.0  0.0  0.0  0.0  0.0  0.0  1.0  0.320581  1  \n",
       "6764  0.0  ...  0.0  84.0  0.0  0.0  0.0  0.0  0.0  1.0  0.429594  1  \n",
       "4874  0.0  ...  0.0  84.0  0.0  0.0  0.0  0.0  0.0  1.0  0.506389  1  \n",
       "6530  0.0  ...  0.0  78.0  0.0  0.0  0.0  0.0  1.0  0.0  0.431327  1  \n",
       "...   ...  ...  ...   ...  ...  ...  ...  ...  ...  ...       ... ..  \n",
       "6671  0.0  ...  0.0  82.0  1.0  0.0  0.0  0.0  0.0  1.0  0.110809  0  \n",
       "2335  0.0  ...  0.0  87.0  0.0  0.0  0.0  0.0  0.0  1.0  0.311202  0  \n",
       "4643  0.0  ...  0.0  83.0  0.0  0.0  0.0  0.0  0.0  1.0  0.311178  0  \n",
       "2102  0.0  ...  0.0  90.0  1.0  0.0  0.0  0.0  0.0  1.0  0.308330  0  \n",
       "6543  0.0  ...  0.0  90.0  0.0  0.0  0.0  0.0  0.0  1.0  0.297925  0  \n",
       "\n",
       "[280 rows x 256 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(x_train0)\n",
    "score = xgb.predict_proba(x_train0)\n",
    "e = {t: score[0:l, t] for t in np.unique(treatment)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(e, open(save_path+'ps1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_s = BaseSClassifier(learner=LogisticRegression(max_iter=3000), control_name='control')\n",
    "learner_s.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5571\n",
      "INFO:causalml:     AUC (Treatment):     0.5287\n",
      "INFO:causalml:Log Loss   (Control):     0.3902\n",
      "INFO:causalml:Log Loss (Treatment):     0.3809\n",
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9460\n",
      "INFO:causalml:     AUC (Treatment):     0.9307\n",
      "INFO:causalml:Log Loss   (Control):     0.1872\n",
      "INFO:causalml:Log Loss (Treatment):     0.2069\n"
     ]
    }
   ],
   "source": [
    "cate_s = learner_s.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "test_learner_s = BaseSClassifier(learner=LogisticRegression(max_iter=3000), control_name='control')\n",
    "test_cate_s = test_learner_s.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'],\n",
    "                y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002649057746630711"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_s-test_cate_s)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.432426105754455e-09"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_s.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_srf = BaseSClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "learner_srf.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5386\n",
      "INFO:causalml:     AUC (Treatment):     0.5275\n",
      "INFO:causalml:Log Loss   (Control):     0.3806\n",
      "INFO:causalml:Log Loss (Treatment):     0.3602\n",
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9844\n",
      "INFO:causalml:     AUC (Treatment):     0.9767\n",
      "INFO:causalml:Log Loss   (Control):     0.2492\n",
      "INFO:causalml:Log Loss (Treatment):     0.2411\n"
     ]
    }
   ],
   "source": [
    "cate_srf = learner_srf.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "test_learner_srf = BaseSClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "test_cate_srf = test_learner_srf.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008212701703910466"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_srf-test_cate_srf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.985827384071108e-07"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_srf.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0090\n",
      "INFO:causalml:Log Loss (Treatment):     0.0082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015971589054146085"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_sxg = BaseSClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "learner_sxg.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_sxg = learner_sxg.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_sxg = BaseSClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "test_cate_sxg = test_learner_sxg.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_sxg-test_cate_sxg)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_t = BaseTClassifier(learner = LogisticRegression(max_iter = 3000), control_name='control')\n",
    "learner_t.fit(X=x_train0, treatment=df_train0['treatment'], y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5511\n",
      "INFO:causalml:     AUC (Treatment):     0.4677\n",
      "INFO:causalml:Log Loss   (Control):     0.3959\n",
      "INFO:causalml:Log Loss (Treatment):     0.5805\n"
     ]
    }
   ],
   "source": [
    "cate_t = learner_t.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9614\n",
      "INFO:causalml:     AUC (Treatment):     0.9999\n",
      "INFO:causalml:Log Loss   (Control):     0.1563\n",
      "INFO:causalml:Log Loss (Treatment):     0.0544\n"
     ]
    }
   ],
   "source": [
    "test_learner_t = BaseTClassifier(learner = LogisticRegression(max_iter = 3000), control_name='control')\n",
    "test_cate_t = test_learner_t.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3502500853049426"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_t-test_cate_t)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9860\n",
      "INFO:causalml:     AUC (Treatment):     0.9972\n",
      "INFO:causalml:Log Loss   (Control):     0.2350\n",
      "INFO:causalml:Log Loss (Treatment):     0.1946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07197757629175905"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_trf = BaseTClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "learner_trf.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_trf = learner_trf.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_trf = BaseTClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "test_cate_trf = test_learner_trf.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_trf-test_cate_trf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0075\n",
      "INFO:causalml:Log Loss (Treatment):     0.0088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29808591308039734"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_txg = BaseTClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "learner_txg.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_txg = learner_txg.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_txg = BaseTClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "test_cate_txg = test_learner_txg.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_txg-test_cate_txg)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(x_train0)\n",
    "score = xgb.predict_proba(x_train0)\n",
    "e = {t: score[0:l, t] for t in np.unique(treatment)}\n",
    "\n",
    "l_test = len(x_test0)\n",
    "score_test = xgb.predict_proba(x_test0)\n",
    "e_test = {t: score[0:l_test, t] for t in np.unique(treatment_test)}\n",
    "\n",
    "treatment = np.array(treatment)\n",
    "treatment_test = np.array(treatment_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     0.9614\n",
      "INFO:causalml:     AUC (Treatment):     0.9999\n",
      "INFO:causalml:Log Loss   (Control):     0.1563\n",
      "INFO:causalml:Log Loss (Treatment):     0.0544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07821502910409286"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_x = BaseXClassifier(outcome_learner=LogisticRegression(max_iter=3000),\n",
    "                            effect_learner=ElasticNetCV(max_iter=3000, random_state=1105))\n",
    "learner_x.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_x = learner_x.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_x = BaseXClassifier(outcome_learner=LogisticRegression(max_iter=3000), \n",
    "                                 effect_learner=ElasticNetCV(max_iter=3000, random_state=1105))\n",
    "test_cate_x = test_learner_x.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_x-test_cate_x)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     0.9860\n",
      "INFO:causalml:     AUC (Treatment):     0.9972\n",
      "INFO:causalml:Log Loss   (Control):     0.2350\n",
      "INFO:causalml:Log Loss (Treatment):     0.1946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11507080185817921"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_xrf = BaseXClassifier(outcome_learner=RandomForestClassifier(random_state=1105, max_depth=6),\n",
    "                            effect_learner=RandomForestRegressor(random_state=1105, max_depth=6))\n",
    "learner_xrf.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_xrf = learner_xrf.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_xrf = BaseXClassifier(outcome_learner=RandomForestClassifier(random_state=1105, max_depth=6), \n",
    "                                 effect_learner=RandomForestRegressor(random_state=1105, max_depth=6))\n",
    "test_cate_xrf = test_learner_xrf.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_xrf-test_cate_xrf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0075\n",
      "INFO:causalml:Log Loss (Treatment):     0.0088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24730096202525068"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_xgb = BaseXClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=6, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=6))\n",
    "learner_xgb.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_xgb = learner_xgb.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_xgb = BaseXClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=6, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=6))\n",
    "test_cate_xgb = test_learner_xgb.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_xgb-test_cate_xgb)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n",
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0062057286046597205"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_r = BaseRClassifier(outcome_learner=LogisticRegression(max_iter=3000),\n",
    "                            effect_learner=ElasticNet(max_iter=3000, random_state=1105))\n",
    "learner_r.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_r = learner_r.predict(X=x_test0, p=e_test)\n",
    "test_learner_r = BaseRClassifier(outcome_learner=LogisticRegression(max_iter=3000), \n",
    "                                 effect_learner=ElasticNet(max_iter=3000, random_state=1105))\n",
    "test_cate_r = test_learner_r.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_r-test_cate_r)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train0)\n",
    "x_test = np.array(x_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n",
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6348465834682693"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_rgb = BaseRClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=5, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=5))\n",
    "learner_rgb.fit(X=x_train, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_rgb = learner_rgb.predict(X=x_test, p=e_test)\n",
    "test_learner_rgb = BaseRClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=5, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=5))\n",
    "test_cate_rgb = test_learner_rgb.fit_predict(X=x_test, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_rgb-test_cate_rgb)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [cate_srf.flatten(), cate_trf.flatten(), cate_xrf.flatten()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd29a2ab890>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(-0.2, 0.2, 10)\n",
    "plt.hist(data1, bins, label = ['S-RF', 'T-RF', 'X-RF'])\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-yling] *",
   "language": "python",
   "name": "conda-env-.conda-yling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
