{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV, MultiTaskElasticNetCV, ElasticNetCV, LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('causalml')\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='../Processed/final/'\n",
    "save_path='../Processed/final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_train, T_train, X_train, W_train)=pickle.load(open(data_path+'YTXW_train.pkl','rb'))\n",
    "(Y_test, T_test, X_test, W_test)=pickle.load(open(data_path+'YTXW_test.pkl','rb'))\n",
    "(Y_val, T_val, X_val, W_val)=pickle.load(open(data_path+'YTXW_val.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dx=pickle.load(open(data_path+'le_dx.pkl','rb'))\n",
    "le_patid=pickle.load(open(data_path+'le_patid.pkl','rb'))\n",
    "selected_patient_feature=['age_onset','obs_win','female']+['race__'+c for c in ['A','B','H','U','W']]\n",
    "rx2id = pickle.load(open(data_path+'drug_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Y,T,W,X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several steps:\n",
    "- Standardize age\n",
    "- Combine demographics with dx information \n",
    "- Set treatment and control group\n",
    "- Output a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def prepare(y, t, w, x, rx2id, target):\n",
    "    patid_temp = list(w['patid'].unique())\n",
    "    temp_le = preprocessing.LabelEncoder()\n",
    "    temp_le.fit(list(patid_temp))\n",
    "    w['row_idx'] = temp_le.transform(w['patid'])\n",
    "    \n",
    "    w_sparse = csr_matrix((w['log_count'], (w['row_idx'], w['phecode3'])))\n",
    "    w = w_sparse.toarray()\n",
    "    \n",
    "    x_temp = np.concatenate((w, x.values), axis=1)\n",
    "    \n",
    "    treatment_train = [0] * len(t)\n",
    "    temp_index = t.index\n",
    "    idx = 0\n",
    "\n",
    "    def get_classes(value):\n",
    "        return [k for k, v in rx2id.items() if v == value]\n",
    "\n",
    "    for i in temp_index:\n",
    "        classes = t.loc[i, 'antiasthma']\n",
    "        if (classes != target):\n",
    "            treatment_train[idx] = 'control'\n",
    "        else:\n",
    "            treatment_train[idx] = 'treatment'\n",
    "        idx += 1\n",
    "        \n",
    "    treatment = pd.DataFrame(treatment_train)\n",
    "    treatment.index = temp_index\n",
    "    treatment.columns = ['treatment']\n",
    "    \n",
    "    y = pd.DataFrame(y)\n",
    "    feature_df = pd.DataFrame(x_temp)\n",
    "    feature_df.index = y.index\n",
    "    \n",
    "    df = pd.concat([y, treatment, t, feature_df], axis=1)\n",
    "    df.index = np.arange(0, len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark (Agonist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 4\n",
    "df_val0 = prepare(Y_val, T_val, W_val, X_val, rx2id, target)\n",
    "df_test0 = prepare(Y_test, T_test, W_test, X_test, rx2id, target)\n",
    "df_train0 = prepare(Y_train, T_train, W_train, X_train, rx2id, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0 = df_train0.iloc[:, 5:]\n",
    "x_test0 = df_test0.iloc[:, 5:]\n",
    "x_val0 = df_val0.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, BaseSRegressor, BaseTRegressor\n",
    "from causalml.metrics import plot_gain, auuc_score\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from causalml.inference.meta import BaseSClassifier, BaseTClassifier, BaseXClassifier, BaseRClassifier\n",
    "from causalml.feature_selection.filters import FilterSelect\n",
    "\n",
    "from causalml.propensity import GradientBoostedPropensityModel\n",
    "from causalml.propensity import compute_propensity_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_train0['treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = [0] * len(t)\n",
    "for i in range(len(t)):\n",
    "    if t[i] == 'control':\n",
    "        treatment[i] = 0\n",
    "    else:\n",
    "        treatment[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = df_test0['treatment']\n",
    "treatment_test = [0] * len(t_test)\n",
    "for i in range(len(t_test)):\n",
    "    if t_test[i] == 'control':\n",
    "        treatment_test[i] = 0\n",
    "    else:\n",
    "        treatment_test[i] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val = df_val0['treatment']\n",
    "treatment_val = [0] * len(t_val)\n",
    "for i in range(len(t_val)):\n",
    "    if t_val[i] == 'control':\n",
    "        treatment_val[i] = 0\n",
    "    else:\n",
    "        treatment_val[i] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=3000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm = LogisticRegression(max_iter = 3000)\n",
    "glm.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred_p = glm.predict_proba(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = t_pred_p[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00953289, 0.03311877, 0.16293793, ..., 0.03869499, 0.07684168,\n",
       "       0.0301836 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5379132195343317"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, random_state=1105)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=6, random_state=1105)\n",
    "rf.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5686127692253988"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = rf.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              random_state=1105, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, random_state=1105, n_estimators=100)\n",
    "xgb.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5168988026669459"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = xgb.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(max_depth = 6, random_state = 1105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=6, random_state=1105)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5647711802282962"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pred_p = gbc.predict_proba(x_val0)\n",
    "lr_probs = t_pred_p[:, 1]\n",
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(l1_ratio=0.1, max_iter=3000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_l1 = LogisticRegression(penalty='elasticnet', max_iter = 3000, solver='saga', l1_ratio=0.1)\n",
    "glm_l1.fit(x_train0, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pred_p = glm_l1.predict_proba(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = t_pred_p[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5399588089503264"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(treatment_val, lr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity score matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = xgb.predict_proba(x_train0)[:, 1]\n",
    "df_train0['score'] = score\n",
    "df_train0['T'] = treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = list(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adrd</th>\n",
       "      <th>treatment</th>\n",
       "      <th>patid</th>\n",
       "      <th>antiasthma</th>\n",
       "      <th>log_count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>score</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>9722</td>\n",
       "      <td>1</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>1232</td>\n",
       "      <td>5</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>2220</td>\n",
       "      <td>1</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>1806</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>9768</td>\n",
       "      <td>2</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>9185</td>\n",
       "      <td>3</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>9752</td>\n",
       "      <td>1</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>3868</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>6972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4886</td>\n",
       "      <td>4</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6771 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adrd  treatment  patid  antiasthma  log_count    0         1         2  \\\n",
       "0        0    control   9722           1   1.945910  0.0  0.000000  0.000000   \n",
       "1        0    control   1232           5   1.386294  0.0  0.000000  1.098612   \n",
       "2        0    control   2220           1   3.583519  0.0  0.000000  0.000000   \n",
       "3        0  treatment   1806           4   0.693147  0.0  0.000000  0.000000   \n",
       "4        0    control   9768           2   1.386294  0.0  0.000000  0.000000   \n",
       "...    ...        ...    ...         ...        ...  ...       ...       ...   \n",
       "6766     0    control   9185           3   3.044522  0.0  0.000000  0.000000   \n",
       "6767     1    control   9752           1   1.609438  0.0  0.000000  0.693147   \n",
       "6768     0    control   3868           1   0.693147  0.0  0.000000  0.693147   \n",
       "6769     0    control   6972           1   0.693147  0.0  0.000000  0.693147   \n",
       "6770     0  treatment   4886           4   0.693147  0.0  0.693147  0.000000   \n",
       "\n",
       "             3         4  ...  241   242  243  244  245  246  247  248  \\\n",
       "0     0.000000  0.000000  ...  0.0  75.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1     1.098612  0.693147  ...  0.0  72.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2     0.000000  0.000000  ...  0.0  74.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3     0.000000  0.000000  ...  0.0  83.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "4     0.000000  0.000000  ...  0.0  84.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "...        ...       ...  ...  ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "6766  0.000000  0.000000  ...  0.0  90.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6767  0.000000  0.000000  ...  0.0  83.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6768  0.000000  0.000000  ...  0.0  88.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "6769  0.000000  0.000000  ...  0.0  89.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "6770  1.098612  0.000000  ...  0.0  83.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "         score  T  \n",
       "0     0.001588  0  \n",
       "1     0.005901  0  \n",
       "2     0.004296  0  \n",
       "3     0.902533  1  \n",
       "4     0.016323  0  \n",
       "...        ... ..  \n",
       "6766  0.020429  0  \n",
       "6767  0.012474  0  \n",
       "6768  0.008146  0  \n",
       "6769  0.004833  0  \n",
       "6770  0.660318  1  \n",
       "\n",
       "[6771 rows x 256 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.match import NearestNeighborMatch, create_table_one\n",
    "\n",
    "psm = NearestNeighborMatch(replace=False,\n",
    "                           ratio=1,\n",
    "                           random_state=42)\n",
    "\n",
    "matched = psm.match(data=df_train0,\n",
    "                    treatment_col='T',\n",
    "                    score_cols=['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adrd</th>\n",
       "      <th>treatment</th>\n",
       "      <th>patid</th>\n",
       "      <th>antiasthma</th>\n",
       "      <th>log_count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>score</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4305</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>5255</td>\n",
       "      <td>4</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>3407</td>\n",
       "      <td>4</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>2680</td>\n",
       "      <td>1</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>2907</td>\n",
       "      <td>3</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.123983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "      <td>7793</td>\n",
       "      <td>5</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adrd  treatment  patid  antiasthma  log_count         0    1    2    3  \\\n",
       "2124     0  treatment   4305           4   3.931826  0.000000  0.0  0.0  0.0   \n",
       "3538     0  treatment   5255           4   3.433987  0.000000  0.0  0.0  0.0   \n",
       "2741     0  treatment   3407           4   1.609438  0.000000  0.0  0.0  0.0   \n",
       "4180     0    control   2680           1   4.094345  0.000000  0.0  0.0  0.0   \n",
       "6465     0    control   2907           3   1.945910  1.098612  0.0  0.0  0.0   \n",
       "2407     0    control   7793           5   2.708050  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "        4  ...  241   242  243  244  245  246  247  248     score  T  \n",
       "2124  0.0  ...  0.0  85.0  1.0  0.0  0.0  0.0  0.0  1.0  0.228209  1  \n",
       "3538  0.0  ...  0.0  84.0  0.0  0.0  0.0  0.0  0.0  1.0  0.119785  1  \n",
       "2741  0.0  ...  0.0  82.0  1.0  0.0  0.0  0.0  0.0  1.0  0.142648  1  \n",
       "4180  0.0  ...  0.0  77.0  0.0  0.0  1.0  0.0  0.0  0.0  0.198596  0  \n",
       "6465  0.0  ...  0.0  83.0  1.0  0.0  0.0  0.0  0.0  1.0  0.123983  0  \n",
       "2407  0.0  ...  0.0  79.0  1.0  0.0  1.0  0.0  0.0  0.0  0.143181  0  \n",
       "\n",
       "[6 rows x 256 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(x_train0)\n",
    "score = xgb.predict_proba(x_train0)\n",
    "e = {t: score[0:l, t] for t in np.unique(treatment)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(e, open(save_path+'ps1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_s = BaseSClassifier(learner=LogisticRegression(max_iter=3000), control_name='control')\n",
    "learner_s.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5460\n",
      "INFO:causalml:     AUC (Treatment):     0.5902\n",
      "INFO:causalml:Log Loss   (Control):     0.3792\n",
      "INFO:causalml:Log Loss (Treatment):     0.5010\n",
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9444\n",
      "INFO:causalml:     AUC (Treatment):     0.9126\n",
      "INFO:causalml:Log Loss   (Control):     0.1862\n",
      "INFO:causalml:Log Loss (Treatment):     0.2772\n"
     ]
    }
   ],
   "source": [
    "cate_s = learner_s.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "test_learner_s = BaseSClassifier(learner=LogisticRegression(max_iter=3000), control_name='control')\n",
    "test_cate_s = test_learner_s.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'],\n",
    "                y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04343987632282827"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_s-test_cate_s)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004059674726682077"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_s.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_srf = BaseSClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "learner_srf.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5375\n",
      "INFO:causalml:     AUC (Treatment):     0.5328\n",
      "INFO:causalml:Log Loss   (Control):     0.3660\n",
      "INFO:causalml:Log Loss (Treatment):     0.5177\n",
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9837\n",
      "INFO:causalml:     AUC (Treatment):     0.9694\n",
      "INFO:causalml:Log Loss   (Control):     0.2419\n",
      "INFO:causalml:Log Loss (Treatment):     0.3346\n"
     ]
    }
   ],
   "source": [
    "cate_srf = learner_srf.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "test_learner_srf = BaseSClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "test_cate_srf = test_learner_srf.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00836723271987844"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_srf-test_cate_srf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3542979644549976e-05"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_srf.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0077\n",
      "INFO:causalml:Log Loss (Treatment):     0.0132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0677429501055442"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_sxg = BaseSClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "learner_sxg.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_sxg = learner_sxg.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_sxg = BaseSClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "test_cate_sxg = test_learner_sxg.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_sxg-test_cate_sxg)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_t = BaseTClassifier(learner = LogisticRegression(max_iter = 3000), control_name='control')\n",
    "learner_t.fit(X=x_train0, treatment=df_train0['treatment'], y=df_train0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.5501\n",
      "INFO:causalml:     AUC (Treatment):     0.6218\n",
      "INFO:causalml:Log Loss   (Control):     0.3797\n",
      "INFO:causalml:Log Loss (Treatment):     0.8605\n"
     ]
    }
   ],
   "source": [
    "cate_t = learner_t.predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9502\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.1792\n",
      "INFO:causalml:Log Loss (Treatment):     0.0452\n"
     ]
    }
   ],
   "source": [
    "test_learner_t = BaseTClassifier(learner = LogisticRegression(max_iter = 3000), control_name='control')\n",
    "test_cate_t = test_learner_t.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38231071959992924"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cate_t-test_cate_t)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     0.9842\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.2335\n",
      "INFO:causalml:Log Loss (Treatment):     0.1904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10401344223578947"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_trf = BaseTClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "learner_trf.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_trf = learner_trf.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_trf = BaseTClassifier(learner=RandomForestClassifier(max_depth=6, random_state=1105), control_name='control')\n",
    "test_cate_trf = test_learner_trf.fit_predict(X=x_test0,\n",
    "                treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_trf-test_cate_trf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group treatment\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0074\n",
      "INFO:causalml:Log Loss (Treatment):     0.0229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3337226418734146"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_txg = BaseTClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "learner_txg.fit(X=x_train0,treatment=df_train0['treatment'],y=df_train0['adrd'])\n",
    "cate_txg = learner_txg.predict(X=x_test0, treatment=df_test0['treatment'])\n",
    "test_learner_txg = BaseTClassifier(learner=XGBClassifier(max_depth=6, random_state=1105, n_estimators=100), control_name='control')\n",
    "test_cate_txg = test_learner_txg.fit_predict(X=x_test0, treatment=df_test0['treatment'], y=df_test0['adrd'])\n",
    "((cate_txg-test_cate_txg)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(x_train0)\n",
    "score = xgb.predict_proba(x_train0)\n",
    "e = {t: score[0:l, t] for t in np.unique(treatment)}\n",
    "\n",
    "l_test = len(x_test0)\n",
    "score_test = xgb.predict_proba(x_test0)\n",
    "e_test = {t: score[0:l_test, t] for t in np.unique(treatment_test)}\n",
    "\n",
    "treatment = np.array(treatment)\n",
    "treatment_test = np.array(treatment_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     0.9502\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.1792\n",
      "INFO:causalml:Log Loss (Treatment):     0.0452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10319156543359748"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_x = BaseXClassifier(outcome_learner=LogisticRegression(max_iter=3000),\n",
    "                            effect_learner=ElasticNetCV(max_iter=3000, random_state=1105))\n",
    "learner_x.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_x = learner_x.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_x = BaseXClassifier(outcome_learner=LogisticRegression(max_iter=3000), \n",
    "                                 effect_learner=ElasticNetCV(max_iter=3000, random_state=1105))\n",
    "test_cate_x = test_learner_x.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_x-test_cate_x)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     0.9842\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.2335\n",
      "INFO:causalml:Log Loss (Treatment):     0.1904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1604556537109791"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_xrf = BaseXClassifier(outcome_learner=RandomForestClassifier(random_state=1105, max_depth=6),\n",
    "                            effect_learner=RandomForestRegressor(random_state=1105, max_depth=6))\n",
    "learner_xrf.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_xrf = learner_xrf.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_xrf = BaseXClassifier(outcome_learner=RandomForestClassifier(random_state=1105, max_depth=6), \n",
    "                                 effect_learner=RandomForestRegressor(random_state=1105, max_depth=6))\n",
    "test_cate_xrf = test_learner_xrf.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_xrf-test_cate_xrf)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:Error metrics for group 1\n",
      "INFO:causalml:     AUC   (Control):     1.0000\n",
      "INFO:causalml:     AUC (Treatment):     1.0000\n",
      "INFO:causalml:Log Loss   (Control):     0.0074\n",
      "INFO:causalml:Log Loss (Treatment):     0.0229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3084432053279013"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_xgb = BaseXClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=6, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=6))\n",
    "learner_xgb.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_xgb = learner_xgb.predict(X=x_test0, treatment=treatment_test, p=e_test)\n",
    "test_learner_xgb = BaseXClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=6, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=6))\n",
    "test_cate_xgb = test_learner_xgb.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_xgb-test_cate_xgb)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n",
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1775468026677443"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_r = BaseRClassifier(outcome_learner=LogisticRegression(max_iter=3000),\n",
    "                            effect_learner=ElasticNet(max_iter=3000, random_state=1105))\n",
    "learner_r.fit(X=x_train0, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_r = learner_r.predict(X=x_test0, p=e_test)\n",
    "test_learner_r = BaseRClassifier(outcome_learner=LogisticRegression(max_iter=3000), \n",
    "                                 effect_learner=ElasticNet(max_iter=3000, random_state=1105))\n",
    "test_cate_r = test_learner_r.fit_predict(X=x_test0, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_r-test_cate_r)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train0)\n",
    "x_test = np.array(x_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n",
      "INFO:causalml:generating out-of-fold CV outcome estimates\n",
      "INFO:causalml:training the treatment effect model for 1 with R-loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.096510470069048"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_rgb = BaseRClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=5, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=5))\n",
    "learner_rgb.fit(X=x_train, treatment=treatment, y=df_train0['adrd'], p=e)\n",
    "cate_rgb = learner_rgb.predict(X=x_test, p=e_test)\n",
    "test_learner_rgb = BaseRClassifier(outcome_learner=XGBClassifier(random_state=1105, max_depth=5, n_estimators =100),\n",
    "                             effect_learner=XGBRegressor(random_state=1105, max_depth=5))\n",
    "test_cate_rgb = test_learner_rgb.fit_predict(X=x_test, treatment=treatment_test, y=df_test0['adrd'], p=e_test)\n",
    "((cate_rgb-test_cate_rgb)**2).mean()**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [cate_srf.flatten(), cate_trf.flatten(), cate_xrf.flatten()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc0b4963550>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(-0.2, 0.2, 10)\n",
    "plt.hist(data1, bins, label = ['S-RF', 'T-RF', 'X-RF'])\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-yling] *",
   "language": "python",
   "name": "conda-env-.conda-yling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
